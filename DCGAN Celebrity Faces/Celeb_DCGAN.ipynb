{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import time\n",
    "import glob\n",
    "import utils\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model \n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found celeba Data\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'input'\n",
    "utils.download_extract('celeba', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_dataset = utils.Dataset('celeba', glob.glob(os.path.join(data_dir, 'img_align_celeba/*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias = False, input_shape = (100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides = (1, 1), padding = 'same', use_bias = False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides = (2, 2), padding = 'same', use_bias = False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(3, (5, 5), strides = (2, 2), padding = 'same', use_bias = False, activation = 'tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 3)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1d80475b10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training = False)\n",
    "\n",
    "plt.imshow(((generated_image[0, :, :, :] + 0.5) * 255).numpy().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides = (2, 2), padding = 'same',\n",
    "                                     input_shape = [28, 28, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides = (2, 2), padding = 'same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00343647]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Losses and Optimizer\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Checkpoints\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer = generator_optimizer,\n",
    "                                 discriminator_optimizer = discriminator_optimizer,\n",
    "                                 generator = generator,\n",
    "                                 discriminator = discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "EPOCHS = 40000\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training = True)\n",
    "\n",
    "      real_output = discriminator(images, training = True)\n",
    "      fake_output = discriminator(generated_images, training = True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training = False)\n",
    "\n",
    "  fig = plt.figure(figsize = (4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(((generated_image[i, :, :, :] + 0.5) * 255).numpy().astype(np.uint8))\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('images/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait = True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait = True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train(celeba_dataset.get_batches(batch_size = BATCH_SIZE), EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
