{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import time\n",
    "import glob\n",
    "import utils\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model \n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found celeba Data\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'input'\n",
    "utils.download_extract('celeba', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_dataset = utils.Dataset('celeba', glob.glob(os.path.join(data_dir, 'img_align_celeba/*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias = False, input_shape = (100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides = (1, 1), padding = 'same', use_bias = False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides = (2, 2), padding = 'same', use_bias = False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(3, (5, 5), strides = (2, 2), padding = 'same', use_bias = False, activation = 'tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 3)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1b0c05f850>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training = False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides = (2, 2), padding = 'same',\n",
    "                                     input_shape = [28, 28, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides = (2, 2), padding = 'same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[4.584223e-05]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Losses and Optimizer\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Checkpoints\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer = generator_optimizer,\n",
    "                                 discriminator_optimizer = discriminator_optimizer,\n",
    "                                 generator = generator,\n",
    "                                 discriminator = discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "EPOCHS = 40000\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training = True)\n",
    "\n",
    "      real_output = discriminator(images, training = True)\n",
    "      fake_output = discriminator(generated_images, training = True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training = False)\n",
    "\n",
    "  fig = plt.figure(figsize = (4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, :])\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait = True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait = True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train(celeba_dataset.get_batches(batch_size = BATCH_SIZE), EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
