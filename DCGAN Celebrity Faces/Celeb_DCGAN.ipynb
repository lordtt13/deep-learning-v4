{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import time\n",
    "import glob\n",
    "import utils\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model \n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found celeba Data\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'input'\n",
    "utils.download_extract('celeba', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_dataset = utils.Dataset('celeba', glob.glob(os.path.join(data_dir, 'img_align_celeba/*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias = False, input_shape = (100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides = (1, 1), padding = 'same', use_bias = False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides = (2, 2), padding = 'same', use_bias = False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding = 'same', use_bias = False, activation = 'tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 3)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd303d216d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training = False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides = (2, 2), padding = 'same',\n",
    "                                     input_shape = [28, 28, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides = (2, 2), padding = 'same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00209515]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Losses and Optimizer\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Checkpoints\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer = generator_optimizer,\n",
    "                                 discriminator_optimizer = discriminator_optimizer,\n",
    "                                 generator = generator,\n",
    "                                 discriminator = discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training = True)\n",
    "\n",
    "      real_output = discriminator(images, training = True)\n",
    "      fake_output = discriminator(generated_images, training = True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training = False)\n",
    "\n",
    "  fig = plt.figure(figsize = (4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0], cmap = 'gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait = True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait = True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train(celeba_dataset.get_batches(batch_size = BATCH_SIZE), EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
