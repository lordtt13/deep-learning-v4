{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model \n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading celeba: 1.44GB [05:17, 4.55MB/s]                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting celeba...\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'input'\n",
    "utils.download_extract('celeba', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(images, alpha = 0.2, dropout = 0.8):\n",
    "    \"\"\"\n",
    "    Create the discriminator network\n",
    "    :param images: Tensor of input image(s)\n",
    "    :param alpha: The leakage amount from the relus.\n",
    "    :param dropout: How much dropout we want for trainning the discriminator\n",
    "    :return: Tuple of (tensor output of the discriminator, tensor logits of the discriminator)\n",
    "    \"\"\"\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(64, 5, strides = 2, padding = 'same')(images)\n",
    "    h1 = tf.keras.layers.maximum([alpha * x, x])\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2D(128, 5, strides = 2, padding = 'same')(h1)\n",
    "    h2 = tf.keras.layers.BatchNormalization(training = True)(h2)\n",
    "    h2 = tf.keras.layers.maximum([alpha * h2, h2])\n",
    "\n",
    "    h3 = tf.keras.layers.Conv2D(256, 5, strides = 2, padding = 'same')(h2)\n",
    "    h3 = tf.keras.layers.BatchNormalization(training = True)(h3)\n",
    "    h3 = tf.keras.layers.maximum([alpha * h3, h3])\n",
    "\n",
    "    flat = tf.keras.layers.Reshape((-1, 4*4*256))(h3)\n",
    "    dropout_layer = tf.keras.layers.Dropout(dropout)(flat)\n",
    "    logits = tf.keras.layers.Dense(1)(dropout_layer)\n",
    "    out = tf.keras.activations.sigmoid(logits)\n",
    "        \n",
    "    return tf.keras.models.Model(x , [out, logits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, out_channel_dim, is_train=True, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Create the generator network\n",
    "    :param z: Input z\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :param is_train: Boolean if generator is being used for training\n",
    "    :param alpha: The leakage amount from the relus.\n",
    "    :return: The tensor output of the generator\n",
    "    \"\"\"\n",
    "    \n",
    "    x = tf.keras.layers.Dense(3*3*512)(z)\n",
    "    h1 = tf.keras.layers.Reshape((-1, 3, 3, 512))(x)\n",
    "    h1 = tf.keras.layers.BatchNormalization(training = is_train)(h1)\n",
    "    h1 = tf.keras.layers.maximum([alpha * h1, h1])\n",
    "    # 3x3x512\n",
    "\n",
    "    h2 = tf.keras.layers.Conv2DTranspose(256, kernel_size = 4, strides = 2, padding = 'same')(h2)\n",
    "    h2 = tf.keras.layers.BatchNormalization(training = is_train)(h2)\n",
    "    h2 = tf.keras.layers.maximum([alpha * h2, h2])\n",
    "    # 6x6x256\n",
    "\n",
    "    h3 = tf.layers.tf.keras.layers.Conv2DTranspose(h2, 128, kernel_size = 4, strides = 2, padding = 'valid')\n",
    "    h3 = tf.keras.layers.BatchNormalization(training = is_train)(h3)\n",
    "    h3 = tf.keras.layers.maximum([alpha * h3, h3])\n",
    "    #14x14x128\n",
    "\n",
    "    # Output layer\n",
    "    logits = tf.keras.layers.Conv2DTranspose(h3, out_channel_dim, kernel_size = 5,strides = 2, padding = 'same')\n",
    "    out = tf.keras.layers.activation.tanh(logits)\n",
    "    # 28x28x5\n",
    "        \n",
    "    return tf.keras.models.Model(x, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
